{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498a50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8fea0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what: HTMLを解析して馬の結果テーブルをDataFrame化する関数\n",
    "# for:  特徴量抽出のため\n",
    "# in:   取得したhtml(.bin)\n",
    "# out:  レース結果テーブル(DataFrame)\n",
    "def parse_horse_html(bin_path):\n",
    "    with open(bin_path, \"rb\") as f:\n",
    "            html_text = f.read().decode(\"EUC-JP\", errors=\"ignore\")\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "\n",
    "    # --- レース成績表の抽出 ---\n",
    "    result_table = soup.find(\"table\", class_=\"db_h_race_results\")\n",
    "    \n",
    "    if not result_table:\n",
    "        raise ValueError(\"馬結果テーブルが見つかりません。\")\n",
    "\n",
    "    rows = result_table.find_all(\"tr\")[1:]  # ヘッダを除外して行ごとにデータを取得\n",
    "    horse_data = []\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        # --- 日付を取得 ---\n",
    "        date_tag = row.find(\"a\", href=re.compile(r\"/race/list/(\\d+)\"))\n",
    "        race_date = re.search(r\"/race/list/(\\d+)\", date_tag[\"href\"]).group(1) if date_tag else None\n",
    "\n",
    "        # --- race idを取得 ---\n",
    "        race_id_tag = row.find(\"a\", href=re.compile(r\"/race/(\\d+)\"))\n",
    "        race_id = re.search(r\"/race/(\\d+)\", race_id_tag[\"href\"]).group(1) if race_id_tag else None\n",
    "\n",
    "        # --- jockey idを取得 ---\n",
    "        jockey_id_tag = row.find(\"a\", href=re.compile(r\"/jockey/result/recent/(\\d+)\"))\n",
    "        jockey_id = re.search(r\"/jockey/result/recent/(\\d+)\", jockey_id_tag[\"href\"]).group(1) if jockey_id_tag else None\n",
    "\n",
    "        horse_data.append([\n",
    "            race_date,                     # レース日付\n",
    "            cols[1].get_text(strip=True),  # 開催\n",
    "            cols[2].get_text(strip=True),  # 天気\n",
    "            cols[3].get_text(strip=True),  # R\n",
    "            race_id,                       # race_id\n",
    "            cols[6].get_text(strip=True),  # 頭数\n",
    "            cols[7].get_text(strip=True),  # 枠番\n",
    "            cols[8].get_text(strip=True),  # 馬番\n",
    "            cols[9].get_text(strip=True),  # オッズ\n",
    "            cols[10].get_text(strip=True), # 人気\n",
    "            cols[11].get_text(strip=True), # 着順\n",
    "            jockey_id,                     # 騎手\n",
    "            cols[13].get_text(strip=True), # 斤量\n",
    "            cols[14].get_text(strip=True), # 距離\n",
    "            cols[16].get_text(strip=True), # 馬場\n",
    "            cols[18].get_text(strip=True), # タイム\n",
    "            cols[19].get_text(strip=True), # 着差\n",
    "            cols[21].get_text(strip=True), # 通過\n",
    "            cols[22].get_text(strip=True), # ペース\n",
    "            cols[23].get_text(strip=True), # 上り\n",
    "            cols[24].get_text(strip=True), # 馬体重\n",
    "            # cols[26].get_text(strip=True), # 勝ち馬\n",
    "            cols[28].get_text(strip=True), # 賞金\n",
    "        ])\n",
    "    horse_df = pd.DataFrame(horse_data, columns=[\n",
    "        \"race_date\", \"place\", \"weather\", \"race_no\", \"race_id\", \"num_of_horses\", \"frame_no\", \"horse_no\",\n",
    "        \"odds\", \"popularity\", \"finish_position\", \"jockey_id\", \"weight\", \"distance\", \"course_condition\",\n",
    "        \"time\", \"margin\", \"passing\", \"pace\", \"final_3f\", \"horse_weight\", \"prize_money\"\n",
    "    ])\n",
    "\n",
    "    return horse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what: 馬結果テーブルの前処理をする関数\n",
    "# for:  AIモデルがうけつけられるようにする\n",
    "# in:   レース結果テーブルの列(.pkl)\n",
    "# out:  レース結果テーブルの列(.pkl)\n",
    "\n",
    "def encoding_weather(weather):\n",
    "    # {晴:0, 曇:1, 雨:2, 小雨:3, 雪:4, その他:np.nan}\n",
    "    if pd.isna(weather): \n",
    "        return np.nan\n",
    "    weather_char = str(weather)\n",
    "    if weather_char == \"晴\":\n",
    "        return 0\n",
    "    elif weather_char == \"曇\":\n",
    "        return 1\n",
    "    elif weather_char == \"小雨\":\n",
    "        return 2\n",
    "    elif weather_char == \"雨\":\n",
    "        return 3\n",
    "    elif weather_char == \"雪\":\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def parse_encoding_distance(distance):\n",
    "    # 例: \"芝1800\" -> (0, 1800)\n",
    "    # {芝:0, ダ:1, 障: 2, その他:np.nan}\n",
    "    if pd.isna(distance): \n",
    "        return (np.nan, np.nan)\n",
    "    \n",
    "    # --- 馬場(state) ---\n",
    "    state_char = str(distance[0])\n",
    "    if state_char == \"芝\":\n",
    "        state = 0\n",
    "    elif state_char == \"ダ\":\n",
    "        state = 1\n",
    "    elif state_char == \"障\":\n",
    "        state = 2\n",
    "    else:\n",
    "        state = np.nan\n",
    "    \n",
    "    # --- 距離(length) ---\n",
    "    try:\n",
    "        long = int(distance[1:])\n",
    "    except:\n",
    "        long = np.nan\n",
    "\n",
    "    return (state, long)\n",
    "\n",
    "def encoding_course_condition(condition):\n",
    "    # {良:0, 稍重:1, 重:2, 不良:3, その他:np.nan}\n",
    "    if pd.isna(condition): \n",
    "        return np.nan\n",
    "    condition_char = str(condition)\n",
    "    if condition_char == \"良\":\n",
    "        return 0\n",
    "    elif condition_char == \"稍重\":\n",
    "        return 1\n",
    "    elif condition_char == \"重\":\n",
    "        return 2\n",
    "    elif condition_char == \"不良\":\n",
    "        return 3\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def time_to_seconds(tstr):\n",
    "    # \"1:51.3\" -> seconds float\n",
    "    try:\n",
    "        if pd.isna(tstr): return np.nan\n",
    "        if \":\" in str(tstr):\n",
    "            mm, ss = str(tstr).split(\":\")\n",
    "            return int(mm) * 60 + float(ss)\n",
    "        else:\n",
    "            return float(tstr)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def parse_margin(margin):\n",
    "    # \"1.1\" -> 1.1 float\n",
    "    # \"クビ\" -> 0.1 float\n",
    "    # \"ハナ\" -> 0.05 float\n",
    "    try:\n",
    "        if pd.isna(margin): return np.nan\n",
    "        s = str(margin)\n",
    "        if s == \"アタマ\":\n",
    "            return 0.2\n",
    "        elif s == \"クビ\":\n",
    "            return 0.1\n",
    "        elif s == \"ハナ\":\n",
    "            return 0.05\n",
    "        else:\n",
    "            return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "# def parse_margin(margin):\n",
    "#     if pd.isna(margin):\n",
    "#         return np.nan\n",
    "\n",
    "#     s = str(margin).strip()\n",
    "\n",
    "#     # 特殊表記\n",
    "#     if s in [\"ハナ\"]:\n",
    "#         return 0.05\n",
    "#     if s in [\"クビ\"]:\n",
    "#         return 0.1\n",
    "#     if s in [\"アタマ\"]:\n",
    "#         return 0.2\n",
    "#     if s in [\"大差\"]:\n",
    "#         return 10.0\n",
    "#     if s in [\"中止\", \"失格\", \"取消\"]:\n",
    "#         return np.nan\n",
    "\n",
    "#     # 分数（例: \"1/2\", \"3/4\"）\n",
    "#     if \"/\" in s:\n",
    "#         try:\n",
    "#             return eval(s)  # \"1/2\" → 0.5\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     # 複合分数（例: \"1 1/4\"）\n",
    "#     if \" \" in s:\n",
    "#         try:\n",
    "#             whole, frac = s.split()\n",
    "#             return float(whole) + eval(frac)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     # 通常の数字（例: \"1.1\"）\n",
    "#     try:\n",
    "#         return float(s)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "def parse_passing(passing):\n",
    "    # \"3-3-2-2\" -> [3,3,2,2]\n",
    "    try:\n",
    "        if pd.isna(passing): return [np.nan, np.nan, np.nan, np.nan]\n",
    "        parts = str(passing).split(\"-\")\n",
    "        return [int(p) for p in parts]\n",
    "    except:\n",
    "        return [np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "def parse_pace(pace):\n",
    "    # \"34.1-44.8\" -> [34.4,44.8]\n",
    "    try:\n",
    "        if pd.isna(pace): return [np.nan, np.nan]\n",
    "        parts = str(pace).split(\"-\")\n",
    "        return [float(p) for p in parts]\n",
    "    except:\n",
    "        return [np.nan, np.nan]\n",
    "\n",
    "def parse_bodyweight(bw):\n",
    "    # \"494(-4)\" -> weight=494, diff=-4\n",
    "    try:\n",
    "        s = str(bw)\n",
    "        if \"(\" in s:\n",
    "            w = int(s.split(\"(\")[0])\n",
    "            diff = int(s.split(\"(\")[1].rstrip(\")\"))\n",
    "        else:\n",
    "            w = int(s)\n",
    "            diff = np.nan\n",
    "        return (w, diff)\n",
    "    except:\n",
    "        return (np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557acb4",
   "metadata": {},
   "source": [
    "## 実行関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c69c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_resultテーブルからhorse_idを取得&保存\n",
    "# horse_ids_df: horse_idのリスト(DataFrame)\n",
    "result_table_path = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\race_result_table.pkl\"\n",
    "df = pd.read_pickle(result_table_path)\n",
    "horse_ids_df = df[\"horse_id\"].unique()\n",
    "pd.Series(horse_ids_df).to_csv(r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_id_list.csv\", index=False, header=False)\n",
    "# # trainer_idとjockey_idのリストも作成\n",
    "# df_trainer_id = df[\"trainer_id\"].unique().tolist()\n",
    "# df_jockey_id = df[\"jockey_id\"].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a75d5f",
   "metadata": {},
   "source": [
    "### horse_idを使って各馬の成績ページ(HTML)をbinファイルとして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2878858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8714/8714 [00:00<00:00, 123150.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# CSVファイルのパス\n",
    "csv_path = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_id_list.csv\"\n",
    "# 保存フォルダのパス\n",
    "save_dir = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_result_html\"\n",
    "\n",
    "# CSVの読み込み\n",
    "df = pd.read_csv(csv_path, header=None)\n",
    "horse_ids = df[0].astype(str).tolist()\n",
    "user_agents = [ # netkeiba.comはアクセス元によってページ構成が変わる→PCブラウザに統一\n",
    "    # Windows Chrome 系\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edg/121.0.2277.83 Safari/537.36\",\n",
    "    # macOS Chrome 系\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "for horse_id in tqdm(horse_ids, total=len(horse_ids)):\n",
    "    url = f\"https://db.netkeiba.com/horse/result/{horse_id}\"\n",
    "\n",
    "    # ファイル保存パス \n",
    "    save_path = os.path.join(save_dir, f\"{horse_id}.bin\")\n",
    "    if os.path.exists(save_path):\n",
    "        continue # 既にそのhorse_idが取得済みならスキップ\n",
    "    else:\n",
    "        try:\n",
    "            res = requests.get(url, headers={\"User-Agent\": random.choice(user_agents)}, timeout=10)\n",
    "            res.raise_for_status()  # エラーがあれば例外を発生\n",
    "\n",
    "            # HTMLをバイナリで保存\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "\n",
    "            # アクセス間隔を少し空ける（サーバー負荷対策）\n",
    "            time.sleep(random.uniform(0.8, 2.0))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {horse_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e0819",
   "metadata": {},
   "source": [
    "### 馬の過去成績テーブルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5315c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8712/8712 [27:54<00:00,  5.20it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 新規178919件を追加しました（合計 178965 件）\n"
     ]
    }
   ],
   "source": [
    "# what: 各馬のbinファイルから馬の過去成績テーブルを抽出し、1つのテーブルに結合しpickleで保存する関数\n",
    "# for:  特徴量の抽出用\n",
    "# in:   取得したhorse_id_list(.csv)とhtml(.bin)\n",
    "# out:  結合されたresult_table(.pickle)\n",
    "\n",
    "csv_path = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_id_list.csv\"\n",
    "result_table_path = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_result_table.pkl\"\n",
    "bin_dir = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_result_html\"\n",
    "df = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "# 既存pickleのhorse_idを確認\n",
    "existing_df = pd.read_pickle(result_table_path)\n",
    "existing_ids = set(existing_df[\"horse_id\"].astype(str))\n",
    "\n",
    "# 新しく解析するhorse_idだけを抽出\n",
    "target_ids = [str(rid) for rid in df[\"horse_id\"] if str(rid) not in existing_ids]\n",
    "\n",
    "new_dfs = []\n",
    "for horse_id in tqdm(target_ids, total=len(target_ids)):\n",
    "    bin_path = os.path.join(bin_dir, f\"{horse_id}.bin\")\n",
    "    if not os.path.exists(bin_path):\n",
    "        print(f\"Missing bin file: {horse_id}\")\n",
    "        continue\n",
    "    try:\n",
    "        # --- HTML解析 ---\n",
    "        df_horse = parse_horse_html(bin_path)\n",
    "        df_horse.insert(0, \"horse_id\", horse_id) # horse_idを先頭列に挿入\n",
    "        new_dfs.append(df_horse)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {horse_id}: {e}\")\n",
    "new_result_df = pd.concat(new_dfs, ignore_index=True)\n",
    "\n",
    "# 追加するテーブルに前処理をしておく\n",
    "new_result_df.drop(columns=[\"place\"], inplace=True)\n",
    "new_result_df[\"weather\"] = new_result_df[\"weather\"].apply(encoding_weather)\n",
    "new_result_df[[\"course_state\", \"distance_length\"]] = new_result_df[\"distance\"].apply(lambda x: pd.Series(parse_encoding_distance(x)))\n",
    "new_result_df.drop(columns=[\"distance\"], inplace=True)\n",
    "new_result_df[\"course_condition\"] = new_result_df[\"course_condition\"].apply(encoding_course_condition)\n",
    "new_result_df[\"time\"] = new_result_df[\"time\"].apply(time_to_seconds)\n",
    "new_result_df[\"margin\"] = new_result_df[\"margin\"].apply(parse_margin)\n",
    "new_result_df[[\"passing_1st\", \"passing_2nd\", \"passing_3rd\", \"passing_4th\"]] = new_result_df[\"passing\"].apply(lambda x: pd.Series(parse_passing(x)))\n",
    "new_result_df.drop(columns=[\"passing\"], inplace=True)\n",
    "new_result_df[[\"pace_1st\", \"pace_2nd\"]] = new_result_df[\"pace\"].apply(lambda x: pd.Series(parse_pace(x)))\n",
    "new_result_df.drop(columns=[\"pace\"], inplace=True)\n",
    "new_result_df[[\"body_weight\",\"body_diff\"]] = new_result_df[\"horse_weight\"].apply(lambda x: pd.Series(parse_bodyweight(x)))\n",
    "new_result_df.drop(columns=[\"horse_weight\"], inplace=True)\n",
    "\n",
    "result_df = pd.concat([existing_df, new_result_df], ignore_index=True)\n",
    "print(f\"✅ 新規{len(new_result_df)}件を追加しました（合計 {len(result_df)} 件）\")\n",
    "result_table = result_df.to_pickle(result_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6df04f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     horse_id race_date  weather race_no       race_id num_of_horses frame_no  \\\n",
      "0  2018104746  20240323      2.0      11  202407010511            16        4   \n",
      "1  2018104746  20240114      0.0      10  202408010510            13        8   \n",
      "2  2018104746  20231223      0.0      10  202309050710            16        7   \n",
      "3  2018104746  20231028      0.0      10  202308020810            15        7   \n",
      "4  2018104746  20231001      1.0      10  202309040910            12        8   \n",
      "5  2018104746  20230708      1.0      11  202307030311            16        6   \n",
      "6  2018104746  20230513      2.0      10  202308010710            16        1   \n",
      "7  2018104746  20230325      2.0      11  202307020511            16        1   \n",
      "8  2018104746  20230212      0.0      10  202309010210            13        8   \n",
      "9  2018104746  20230109      0.0      10  202307010410            16        6   \n",
      "\n",
      "  horse_no  odds popularity  ... course_state distance_length passing_1st  \\\n",
      "0        8   9.8          5  ...            1            1900        11.0   \n",
      "1       12  85.3          8  ...            1            1800        10.0   \n",
      "2       14  13.2          4  ...            1            1800        12.0   \n",
      "3       14   3.0          1  ...            1            1800         6.0   \n",
      "4       12   7.0          4  ...            1            1800         9.0   \n",
      "5       12  18.2          7  ...            1            1800        11.0   \n",
      "6        1   7.6          4  ...            1            1800        12.0   \n",
      "7        2   6.3          4  ...            1            1900         6.0   \n",
      "8       12   9.9          5  ...            1            1800         7.0   \n",
      "9       12  40.4          8  ...            1            1800        11.0   \n",
      "\n",
      "   passing_2nd  passing_3rd  passing_4th pace_1st pace_2nd  body_weight  \\\n",
      "0         11.0         11.0         10.0     29.1     36.4        490.0   \n",
      "1         11.0         12.0         10.0     37.1     36.1        494.0   \n",
      "2         13.0         11.0         10.0     36.9     37.9        494.0   \n",
      "3          5.0          6.0          3.0     36.0     38.0        496.0   \n",
      "4          9.0          7.0          7.0     36.4     37.3        494.0   \n",
      "5         10.0         10.0         10.0     38.1     36.5        494.0   \n",
      "6         10.0         12.0          7.0     36.6     38.5        496.0   \n",
      "7          7.0          7.0          7.0     30.4     35.9        494.0   \n",
      "8          6.0          5.0          4.0     37.2     37.4        494.0   \n",
      "9         13.0         12.0         12.0     36.9     37.7        500.0   \n",
      "\n",
      "   body_diff  \n",
      "0       -4.0  \n",
      "1        0.0  \n",
      "2       -2.0  \n",
      "3        2.0  \n",
      "4        0.0  \n",
      "5       -2.0  \n",
      "6        2.0  \n",
      "7        0.0  \n",
      "8       -6.0  \n",
      "9       -2.0  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "horse_table_path = r\"C:\\Users\\yasak\\Desktop\\mykeibaAI_ver1p0\\data\\horse_result_table.pkl\"\n",
    "horse_table_df = pd.read_pickle(horse_table_path)\n",
    "\n",
    "print(horse_table_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d24398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
